Goal
Integrate a fully-local, open-source AI assistant into my existing Vite + React (TypeScript) real-estate-lead-tracking web-app. The assistant must:

Chat in natural language (TR + EN)

Answer questions about the Leads and Takipte PostgreSQL tables (via Drizzle ORM)

Generate on-demand summaries & Chart.js visuals for any query (e.g. “show Instagram leads by week”)

Work without any paid API key – model runs locally/on-prem

Be packaged so it deploys the same way the current Express + Vite stack does (Dev: VS Code; Prod: Neon + Render)

Implementation constraints
Use Ollama (or an equivalent self-hosted engine) to serve an open-source LLM such as Llama 3 Instruct (8 B) or Phi-3 Mini.

Wrap the model with LangChain JS so we can:

Inject PostgreSQL retriever (Drizzle → LangChain Toolkit)

Convert natural-language questions into SQL, run via Drizzle, and stream results back to the LLM for reasoning

Expose a single REST endpoint POST /api/ai/query on the existing Express server.

Add a React chat widget (shadcn/ui + Radix primitives) that calls this endpoint, shows streaming text, and renders Chart.js when the response JSON contains a chartSpec.

Keep everything TypeScript, eslint-clean, and tree-shaken.

Concrete tasks for you
Backend
1.1 Add @langchain/community, pg, dotenv, and ollama client libs
1.2 Create src/server/llm/ollama.ts that spins up (or connects to) a local Ollama container and exposes invoke(prompt, context)
1.3 Create src/server/routes/ai.ts with the /api/ai/query handler:

Accepts { query:string }

Builds LangChain pipeline: SQLDatabaseChain (Drizzle adapter) ➜ LLM

Streams back { type:"text", chunk:string } or { type:"chart", chartSpec } events

Frontend
2.1 Create ChatDrawer.tsx (shadcn Drawer) with a message list and textarea
2.2 Implement SSE or WebSocket client to consume streamed events
2.3 Render text chunks; when a chart event arrives, mount a <LeadChart> component that feeds the provided chartSpec to chart.js/auto with 3-D plugin

Dev & Prod scripts

pnpm dev:ai – start Ollama (pull model if missing), then pnpm dev for Vite + api

Dockerfile: multi-stage build (builder → slim node 20) + Ollama install; expose 3000

Docs

Update README.md with: local setup, environment variables, how to add new models, sample NL queries

Smoke tests

Jest test that asks “How many Satılık leads did we get last month from Instagram?” and expects non-empty numeric answer.

Return only the modified/added files with code, followed by a quick “how to run” section.